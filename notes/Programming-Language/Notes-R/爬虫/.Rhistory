plot.title = element_text(face = 'bold', size = 14),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(hjust = 0, size = 10, margin = margin(2,0,0,0,'pt')),
plot.margin = margin(12,10,12,0,'pt'),
legend.position = 'top',
legend.justification = 'left',
legend.margin = margin(4,0,0,0,'pt'),
legend.key.size = unit(1,'lines'),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10, margin = margin(0,0,0,0,'pt')),
axis.text = element_text(size = 10, margin = margin(2,0,2,0,'pt')),
axis.ticks.length = unit(-4,'pt')
)
# 自定义柱状图主题
theme_bar <- theme_economist_white() +
theme(text = element_text(family = 'YaHei'), # 所有的文本字体
plot.title = element_text(face = 'bold', size = 14),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(hjust = 0, size = 10,
margin = margin(0,0,0,0,'pt')),
plot.margin = margin(12,0,12,10,'pt'),
legend.position = 'top',
legend.justification = 'left',
legend.margin = margin(4,0,0,0,'pt'),
legend.key.size = unit(0.7,'lines'),
legend.title = element_blank(),
legend.text = element_text(size = 10, margin = margin(0,8,0,4,'pt')),
axis.text = element_text(size = 10),
axis.ticks.length = unit(0,'pt') # 不要坐标轴须
)
url <- 'http://news.baidu.com/ns?cl=2&rn=20&tn=news&word=%E7%89%B9%E6%9C%97%E6%99%AE&ie=utf-8'
httr_web <- url %>% read_html()
title <- httr_web %>% html_nodes('h3>a') %>% html_text(trim = T)
httr_web <- url %>% read_html(encoding = 'utf-8')
url <- 'http://news.baidu.com/ns?cl=2&rn=20&tn=news&word=%E7%89%B9%E6%9C%97%E6%99%AE&ie=utf-8'
httr_web <- url %>% read_html(encoding = 'utf-8')
title <- httr_web %>% html_nodes('h3>a') %>% html_text(trim = T)
title <- httr_web %>% html_nodes('.c-title a') %>% html_text(trim = T)
title <- httr_web %>% html_nodes('.c-title a')
title <- httr_web %>% html_node('.c-title a')
url <- 'http://news.baidu.com/ns?cl=2&rn=20&tn=news&word=%E7%89%B9%E6%9C%97%E6%99%AE&ie=utf-8'
httr_web <- url %>% read_html(encoding = 'utf-8')
View(httr_web)
# 抓取金州勇士队的球员数据
url <- 'http://www.stat-nba.com/team/GSW.html'
table <- url %>% read_html()
View(table)
url <- 'http://news.baidu.com/ns?cl=2&rn=20&tn=news&word=%E7%89%B9%E6%9C%97%E6%99%AE&ie=utf-8'
httr_web <- url %>% read_html(encoding = 'utf-8')
View(httr_web)
u <- "http://news.baidu.com/"
session <- html_session(u) # 创建会话
forms <- html_form(session) # 提取表单
forms # 查看表单
u <- "http://news.baidu.com/"
u <- "http://news.baidu.com/"
session <- html_session(u) # 创建会话
forms <- html_form(session) # 提取表单
forms # 查看表单
url <- 'http://news.baidu.com/ns?cl=2&rn=20&tn=news&word=%E7%89%B9%E6%9C%97%E6%99%AE&ie=utf-8'
httr_web <- url %>% read_html(encoding = 'utf-8')
View(httr_web)
title <- httr_web %>% html_node('.c-title a')
title <- httr_web %>% html_node('.c-title a') %>% html_text(trim = T)
url <- 'https://www.baidu.com/s?rtt=1&bsst=1&cl=2&tn=news&rsv_dl=ns_pc&word=%E7%89%B9%E6%9C%97%E6%99%AE'
httr_web <- url %>% read_html(encoding = 'utf-8')
View(httr_web)
url <- 'https://www.baidu.com/s?rtt=1&bsst=1&cl=2&tn=news&rsv_dl=ns_pc&word=%E7%89%B9%E6%9C%97%E6%99%AE'
httr_web <- url %>% read_html(encoding = 'utf-8')
View(httr_web)
# 抓取温州各个行政区域的坐标
library(jsonlite)
name='温州'
encoding_name <- iconv(enc2utf8(name),from='utf-8',to='ISO-8859-1',sub= "byte") %>%
str_replace_all('><','%') %>% str_sub(1,18) %>% str_to_upper() %>% str_replace('<','%')
subdistrict_num=1
key_str='你的API'
url0 <- 'http://restapi.amap.com/v3/config/district?'
url <- paste0(url0, 'keywords=',encoding_name,'&','subdistrict=',subdistrict_num,'&','key=',key_str)
url
## global options
knitr::opts_chunk$set(
fig.width = 6, fig.asp = 0.618,
out.width = "80%", fig.align = "center",
fig.path = 'Figures/', fig.show = "hold",
warn = 1, warning = FALSE, message = FALSE, echo = TRUE,
comment = '', collapse = F,
cache = T, cache.comments = F, autodep = TRUE
)
## use necessary packages
library('pacman')
p_load(tidyverse, lubridate, data.table, # 数据整理
ggthemes, showtext, gridExtra, igraph, ggraph, # 可视化
lmtest, plm, orcutt, stats, forecast, zoo, # 统计分析
rvest, httr, xml2, # 爬虫
sqldf, DT, # I/O
jiebaR, wordcloud2, webshot, htmlwidgets, tidytext # 文本分析
)
options(sqldf.driver = "SQLite")
## pdf中图形内部的中文字体设置
pdf.options(family = "GB1")
# 安装字体文件
# font_add('YaHei','MS YaHei.ttf')
windowsFonts(YaHei = windowsFont("Microsoft YaHei"))
showtext_auto(enable = TRUE)
# 包含图的代码块需要fig.showtext = TRUE选项
# ggplot2图形需要在主题中显式指定中文字体才能正常显示图中的中文
## 自定义一般图形主题
mytheme <- theme_economist_white() +
theme(text = element_text(family = 'YaHei'),
plot.title = element_text(face = 'bold', size = 14),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(hjust = 0, size = 10, margin = margin(2,0,0,0,'pt')),
plot.margin = margin(12,10,12,0,'pt'),
legend.position = 'top',
legend.justification = 'left',
legend.margin = margin(4,0,0,0,'pt'),
legend.key.size = unit(1,'lines'),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10, margin = margin(0,0,0,0,'pt')),
axis.text = element_text(size = 10, margin = margin(2,0,2,0,'pt')),
axis.ticks.length = unit(-4,'pt')
)
# 自定义柱状图主题
theme_bar <- theme_economist_white() +
theme(text = element_text(family = 'YaHei'), # 所有的文本字体
plot.title = element_text(face = 'bold', size = 14),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(hjust = 0, size = 10,
margin = margin(0,0,0,0,'pt')),
plot.margin = margin(12,0,12,10,'pt'),
legend.position = 'top',
legend.justification = 'left',
legend.margin = margin(4,0,0,0,'pt'),
legend.key.size = unit(0.7,'lines'),
legend.title = element_blank(),
legend.text = element_text(size = 10, margin = margin(0,8,0,4,'pt')),
axis.text = element_text(size = 10),
axis.ticks.length = unit(0,'pt') # 不要坐标轴须
)
url <- 'http://www.stat-nba.com/team/GSW.html'
table <- url %>% read_html() %>% html_table()
table[[1]]
table[[2]]
url <- 'https://cn.investing.com/indices/baltic-dry-historical-data'
# 下载网页到本地，包括文字、表格，甚至广告
download.file(url, "./temporary.html")
# 解析网页，并读取网页中的表格
table <- './temporary.html' %>%
read_html(encoding = 'UTF-8') %>%
# html_node("table") %>%
html_table(header = T, fill = T)
View(table)
View(table[[1]])
View(table[[2]])
View(table[[1]])
View(table[[3]])
View(table[[4]])
View(table[[5]])
View(table[[10]])
View(table[[14]])
vignette("selectorgadget")
# 然后下面代码分别获取了ateam这个网页里<center>标签里<td>的全部内容
ateam %>% html_nodes("center") %>% html_nodes("td")
ateam <- read_html("http://www.boxofficemojo.com/movies/?id=ateam.htm")
# 然后下面代码分别获取了ateam这个网页里<center>标签里<td>的全部内容
ateam %>% html_nodes("center") %>% html_nodes("td")
# 获取ateam这个网页里<center>标签里<font>的全部内容
ateam %>% html_nodes("center") %>% html_nodes("font")
#下面两行代码都可以获得该网页中第一个<table>标签（由extract2(1)或`[[`(1)获取）中的所有<img>标签里的内容，
ateam %>% html_nodes("table") %>% extract2(1) %>% html_nodes("img")
# 接着官方例子中还给出了获取特定序位的html标签的方法，用到了magrittr包里的extract2函数：
library(magrittr)
#下面两行代码都可以获得该网页中第一个<table>标签（由extract2(1)或`[[`(1)获取）中的所有<img>标签里的内容，
ateam %>% html_nodes("table") %>% extract2(1) %>% html_nodes("img")
ateam %>% html_nodes("table") %>% `[[`(1) %>% html_nodes("img")
#同理我们也可以获得网页里前两个<table>标签储存的所有<img>标签里的内容：
ateam %>% html_nodes("table") %>% `[`(1:2) %>% html_nodes("img")
ateam %>% html_nodes("table") %>% extract(1:2) %>% html_nodes("img")
gurl <- "http://cs.ganji.com/fang5/yuhuashazitang/o1/"
gurl <- "http://cs.ganji.com/fang5/yuhuashazitang/o1/"
getData <- function(gurl){
# 抓取赶集网二手房源单页的数据
# 赶集网首页筛选长沙-雨花区-砂子塘的二手房源，获得链接，o1为页数
tmp <- gurl %>% html_session() %>%
read_html(encoding = "utf-8") %>%
html_nodes("div.f-main-list>div>div")
# 单个房源的puid
puid <- tmp %>% html_attr("id")
# 单个房源的链接
itemURL <- tmp %>% html_attr("href") %>%
gsub(pattern="/fang5", replacement="http://cs.ganji.com/fang5")
# 缩略图链接
smallImg <- tmp %>% html_nodes("dl>dt>div>a>img") %>% html_attr("src")
# 标题
iTitle <- tmp %>% html_nodes("dl>dd>a") %>% html_attr("title")
# 户型
iLayout <- tmp %>% html_nodes("dl>dd[data-huxing]") %>% html_attr("data-huxing")
# 面积
iArea <- tmp %>% html_nodes("dl>dd[data-huxing]") %>%
html_attr("data-area") %>%
gsub(pattern="[^0-9]",replacement="")
# 筛选朝向等数据
iTmp <- tmp %>% html_nodes("dl>dd[data-huxing]>span") %>% html_text()
iOrientation <- iTmp[seq(from=5,to=length(iTmp),by=9)] # 提取朝向
iFloor <- iTmp[seq(from=7,to=length(iTmp),by=9)] %>% # 提取楼层
gsub(pattern="\n",replacement="")
iDecoration <- iTmp[seq(from=9,to=length(iTmp),by=9)] # 提取装修
# 提取地址
iAddr <- tmp %>% html_nodes("dl>dd>span.area") %>% html_text() %>%
gsub(pattern="\n",replacement=" ") %>%
gsub(pattern=" ",replacement="")
# 提取价格
iPrice <- tmp %>% html_nodes("dl>dd>div.price>span:first-child") %>% html_text()
# 提取单价
iTime <- tmp %>% html_nodes("dl>dd>div.time") %>% html_text() %>%
gsub(pattern="[^0-9]",replacement="") %>% as.numeric()
# 合并数据框
iData <- data.frame(puid=puid,
iLayout=iLayout,
iArea=iArea,
iPrice=iPrice,
iTime=iTime,
# iDecoration=iDecoration,
iFloor=iFloor,
iOrientation=iOrientation,
itemURL=itemURL,
smallImg=smallImg,
iTitle=iTitle,
iAddr=iAddr,
stringsAsFactors=FALSE)
# 返回数据框
return(iData)
}
result <- getData(gurl)
gurl <- "http://cs.ganji.com/fang5/yuhuashazitang/o1/"
getData <- function(gurl){
# 抓取赶集网二手房源单页的数据
# 赶集网首页筛选长沙-雨花区-砂子塘的二手房源，获得链接，o1为页数
tmp <- gurl %>% html_session() %>%
read_html(encoding = "utf-8") %>%
html_nodes("div.f-main-list>div>div")
# 单个房源的puid
puid <- tmp %>% html_attr("id")
# 单个房源的链接
itemURL <- tmp %>% html_attr("href") %>%
gsub(pattern="/fang5", replacement="http://cs.ganji.com/fang5")
# 缩略图链接
smallImg <- tmp %>% html_nodes("dl>dt>div>a>img") %>% html_attr("src")
# 标题
iTitle <- tmp %>% html_nodes("dl>dd>a") %>% html_attr("title")
# 户型
iLayout <- tmp %>% html_nodes("dl>dd[data-huxing]") %>% html_attr("data-huxing")
# 面积
iArea <- tmp %>% html_nodes("dl>dd[data-huxing]") %>%
html_attr("data-area") %>%
gsub(pattern="[^0-9]",replacement="")
# 筛选朝向等数据
iTmp <- tmp %>% html_nodes("dl>dd[data-huxing]>span") %>% html_text()
iOrientation <- iTmp[seq(from=5,to=length(iTmp),by=9)] # 提取朝向
iFloor <- iTmp[seq(from=7,to=length(iTmp),by=9)] %>% # 提取楼层
gsub(pattern="\n",replacement="")
iDecoration <- iTmp[seq(from=9,to=length(iTmp),by=9)] # 提取装修
# 提取地址
iAddr <- tmp %>% html_nodes("dl>dd>span.area") %>% html_text() %>%
gsub(pattern="\n",replacement=" ") %>%
gsub(pattern=" ",replacement="")
# 提取价格
iPrice <- tmp %>% html_nodes("dl>dd>div.price>span:first-child") %>% html_text()
# 提取单价
iTime <- tmp %>% html_nodes("dl>dd>div.time") %>% html_text() %>%
gsub(pattern="[^0-9]",replacement="") %>% as.numeric()
# 合并数据框
iData <- data.frame(puid=puid,
iLayout=iLayout,
iArea=iArea,
iPrice=iPrice,
iTime=iTime,
# iDecoration=iDecoration,
iFloor=iFloor,
iOrientation=iOrientation,
itemURL=itemURL,
smallImg=smallImg,
iTitle=iTitle,
iAddr=iAddr,
stringsAsFactors=FALSE)
# 返回数据框
return(iData)
}
result <- getData(gurl)
rm(list = ls())
# install.packages(XML)
library(XML)
# install.packages(bitops)
library(bitops)
# install.packages(RCurl)
library(RCurl)
temp = getURL('http://movie.douban.com/subject/26862829/?from=subject-page')
fanghua = htmlParse(temp)
fanghua
nbadata = xmlParse(file = "./nbaplayer.xml")
nbadata = xmlParse(file = "./nbaplayer.xml")
nbadata
read_html('http://movie.douban.com/subject/26862829/') %>% html_nodes(xpath = "//h1//span")
char = 'Golden states worries is the NBA champion in 2017'
URLencode(char, reserve = TRUE)
##  [1] "Golden%20states%20worries%20is%20the%20NBA%20champion%20in%202017"
URLdecode(char)
## global options
knitr::opts_chunk$set(
fig.width = 6, fig.asp = 0.618,
out.width = "80%", fig.align = "center",
fig.path = 'Figures/', fig.show = "hold",
warn = 1, warning = FALSE, message = FALSE, echo = TRUE,
comment = '', collapse = F,
cache = T, cache.comments = F, autodep = TRUE
)
## use necessary packages
library('pacman')
p_load(tidyverse, lubridate, data.table, # 数据整理
ggthemes, showtext, gridExtra, igraph, ggraph, # 可视化
lmtest, plm, orcutt, stats, forecast, zoo, # 统计分析
rvest, httr, xml2, # 爬虫
sqldf, DT, # I/O
jiebaR, wordcloud2, webshot, htmlwidgets, tidytext # 文本分析
)
options(sqldf.driver = "SQLite")
## pdf中图形内部的中文字体设置
pdf.options(family = "GB1")
# 安装字体文件
# font_add('YaHei','MS YaHei.ttf')
windowsFonts(YaHei = windowsFont("Microsoft YaHei"))
showtext_auto(enable = TRUE)
# 包含图的代码块需要fig.showtext = TRUE选项
# ggplot2图形需要在主题中显式指定中文字体才能正常显示图中的中文
## 自定义一般图形主题
mytheme <- theme_economist_white() +
theme(text = element_text(family = 'YaHei'),
plot.title = element_text(face = 'bold', size = 14),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(hjust = 0, size = 10, margin = margin(2,0,0,0,'pt')),
plot.margin = margin(12,10,12,0,'pt'),
legend.position = 'top',
legend.justification = 'left',
legend.margin = margin(4,0,0,0,'pt'),
legend.key.size = unit(1,'lines'),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10, margin = margin(0,0,0,0,'pt')),
axis.text = element_text(size = 10, margin = margin(2,0,2,0,'pt')),
axis.ticks.length = unit(-4,'pt')
)
# 自定义柱状图主题
theme_bar <- theme_economist_white() +
theme(text = element_text(family = 'YaHei'), # 所有的文本字体
plot.title = element_text(face = 'bold', size = 14),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(hjust = 0, size = 10,
margin = margin(0,0,0,0,'pt')),
plot.margin = margin(12,0,12,10,'pt'),
legend.position = 'top',
legend.justification = 'left',
legend.margin = margin(4,0,0,0,'pt'),
legend.key.size = unit(0.7,'lines'),
legend.title = element_blank(),
legend.text = element_text(size = 10, margin = margin(0,8,0,4,'pt')),
axis.text = element_text(size = 10),
axis.ticks.length = unit(0,'pt') # 不要坐标轴须
)
url <- 'http://www.stat-nba.com/team/GSW.html'
table <- url %>% read_html() %>% html_table()
table[[1]]
table[[2]]
url <- 'https://cn.investing.com/indices/baltic-dry-historical-data'
url <- "http://data.eastmoney.com/cjsj/hyzs_EMI00107664.html"
# 下载网页到本地，包括文字、表格，甚至广告
download.file(url, "./temporary.html")
url <- "http://data.eastmoney.com/cjsj/hyzs_EMI00107664.html"
# 解析网页，并读取网页中的表格
table <- './temporary.html' %>%
read_html(encoding = 'UTF-8') %>%
html_table(header = T, fill = T)
# 解析网页，并读取网页中的表格
table <- url %>%
read_html(encoding = 'UTF-8') %>%
html_table(header = T, fill = T)
DT::datatable(table[[1]])
url <- "http://www.customs.gov.cn/customs/302249/zfxxgk/2799825/302274/302275/3511730/index.html"
# 下载网页到本地，包括文字、表格，甚至广告
download.file(url, "./temporary.html")
# 解析网页，并读取网页中的表格
table <- url %>%
read_html(encoding = 'UTF-8') %>%
html_table(header = T, fill = T)
u <- "https://movie.douban.com/"
session <- html_session(u) # 创建会话
forms <- html_form(session) # 提取表单
forms # 查看表单
form <- forms[[1]] # forms 中的第一个列表是我们的目标列表
form
# 在上面的结果中，只有'search_text'的冒号后为空
# 这表明 ‘search_text’ 还没有填充任何值，而我们的任务就是把它填上
filled_form <- set_values(form, search_text = "流浪地球") # 填写表单
filled_form
session2 <- submit_form(session, form = filled_form) # 根据填写的表单，创建新会话
session2$url # 查看新会话的 url
iconv(URLdecode(session2$url), "UTF8") # 获得重新编码的网址，用以爬虫
char = "Golden states worries is the NBA champion in 2017"
(charEncode = URLencode(char, reserved = T))
(charDecode = URLdecode(charEncode))
?URLencode
?URLdecode
char = "Golden states worries is the NBA champion in 2017"
(charEncode = URLencode(char, reserved = T))
(charDecode = URLdecode(charEncode))
session2$url # 查看新会话的 url
iconv(URLdecode(session2$url), "UTF8") # 获得重新编码的网址，用以爬虫
?iconv
url2 <- iconv(URLdecode(session2$url), "UTF8") # 获得重新编码的网址，用以爬虫
a <- url2 %>% read_html()
a
url2
a <- url2 %>% read_html() %>% html_nodes("div.sc-bZQynM gczMis sc-bxivhb jDZFxE")
a
a <- url2 %>% read_html() %>% html_nodes("div.sc-bZQynM")
a
url2 <- iconv(URLdecode(session2$url), "UTF8") # 获得重新编码的网址，用以爬虫
a <- url2 %>% read_html() %>% html_nodes("div.sc-bZQynM")
a
a <- url2 %>% read_html() %>% html_nodes("div.item-root")
a
a <- url2 %>% read_html()
a
a[1]
a[2]
a <- url2 %>% read_html() %>% html_nodes("div a")
a
a <- url2 %>% read_html() %>% html_nodes(xpath = "sc-bZQynM gczMis sc-bxivhb jDZFxE")
a
a <- url2 %>% read_html() %>% html_nodes("div.title>a")
a
a <- url2 %>% read_html() %>% html_text()
a
print(a)
a <- url2 %>% read_html() %>% write_html("successOrFail.html")
a <- url2 %>% read_html() %T>% write_html("successOrFail.html")
## global options
knitr::opts_chunk$set(
fig.width = 6, fig.asp = 0.618,
out.width = "80%", fig.align = "center",
fig.path = 'Figures/', fig.show = "hold",
warn = 1, warning = FALSE, message = FALSE, echo = TRUE,
comment = '', collapse = F,
cache = T, cache.comments = F, autodep = TRUE
)
## use necessary packages
library('pacman')
p_load(tidyverse, lubridate, data.table, magrittr, # 数据整理
ggthemes, showtext, gridExtra, igraph, ggraph, # 可视化
lmtest, plm, orcutt, stats, forecast, zoo, # 统计分析
rvest, httr, xml2, # 爬虫
sqldf, DT, # I/O
jiebaR, wordcloud2, webshot, htmlwidgets, tidytext # 文本分析
)
options(sqldf.driver = "SQLite")
## pdf中图形内部的中文字体设置
pdf.options(family = "GB1")
# 安装字体文件
# font_add('YaHei','MS YaHei.ttf')
windowsFonts(YaHei = windowsFont("Microsoft YaHei"))
showtext_auto(enable = TRUE)
# 包含图的代码块需要fig.showtext = TRUE选项
# ggplot2图形需要在主题中显式指定中文字体才能正常显示图中的中文
## 自定义一般图形主题
mytheme <- theme_economist_white() +
theme(text = element_text(family = 'YaHei'),
plot.title = element_text(face = 'bold', size = 14),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(hjust = 0, size = 10, margin = margin(2,0,0,0,'pt')),
plot.margin = margin(12,10,12,0,'pt'),
legend.position = 'top',
legend.justification = 'left',
legend.margin = margin(4,0,0,0,'pt'),
legend.key.size = unit(1,'lines'),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10, margin = margin(0,0,0,0,'pt')),
axis.text = element_text(size = 10, margin = margin(2,0,2,0,'pt')),
axis.ticks.length = unit(-4,'pt')
)
# 自定义柱状图主题
theme_bar <- theme_economist_white() +
theme(text = element_text(family = 'YaHei'), # 所有的文本字体
plot.title = element_text(face = 'bold', size = 14),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(hjust = 0, size = 10,
margin = margin(0,0,0,0,'pt')),
plot.margin = margin(12,0,12,10,'pt'),
legend.position = 'top',
legend.justification = 'left',
legend.margin = margin(4,0,0,0,'pt'),
legend.key.size = unit(0.7,'lines'),
legend.title = element_blank(),
legend.text = element_text(size = 10, margin = margin(0,8,0,4,'pt')),
axis.text = element_text(size = 10),
axis.ticks.length = unit(0,'pt') # 不要坐标轴须
)
a <- url2 %>% read_html() %T>% write_html("successOrFail.html")
blogdown:::preview_site()
library('pacman')
p_load(# data processing
tidyverse, lubridate, data.table, magrittr,
# web crawler
rvest, reticulate, httr)
