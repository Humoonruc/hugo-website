---
title: "线性回归分析"
subtitle: ''
author: "Humoon"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    fig_caption: yes
    theme: united
    highlight: haddock
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: FALSE
  rticles::ctex:
    df_print: default
    fig_caption: yes
    number_sections: false
  word_document:
    fig_caption: yes
    toc: yes
    toc_depth: 3
    reference_docx: 
  pdf_document:
    toc: yes
    toc_depth: '2'
documentclass: ctexart
classoption: hyperref,
---

```{r setup, include = FALSE}
## global options
knitr::opts_chunk$set(
  fig.width = 7, fig.asp = 0.618,
  out.width = "90%", fig.align = "center",
  fig.path = 'Figures/', fig.show = "hold",
  warn = 1, warning = FALSE, message = FALSE,
  echo = TRUE, comment = '#', collapse = F,
  cache = T, cache.comments = F,
  autodep = TRUE
)

## use necessary packages
library('pacman')
p_load(
  # statistics
  BSDA, maxLik, 
  # data processing
  tidyverse, lubridate, data.table, magrittr,
  # visualization
  ggthemes, showtext, gridExtra,
  # 可交互表格 DT::datatable()
  DT,
  # I/O 
  sqldf,
  # web crawler
  XML, rvest, httr, reticulate
  )

## database engine
options(sqldf.driver = "SQLite")

## plotting
# 包含图的代码块需要fig.showtext = TRUE选项
showtext_auto(enable = TRUE)
# ggplot2图形需要在主题中显式指定中文字体才能正常显示图中的中文
windowsFonts(YaHei = windowsFont("Microsoft YaHei"))
# pdf中图形内部的中文字体设置
pdf.options(family = "GB1")

## 自定义图形主题
# common template
mytheme <- theme_economist_white() +
  theme(
    text = element_text(family = 'YaHei'),
    plot.title = element_text(face = 'bold', size = 14),
    plot.subtitle = element_text(size = 12),
    plot.caption = element_text(
      hjust = 0,
      size = 10,
      margin = margin(2, 0, 0, 0, 'pt')
    ),
    plot.margin = margin(12, 10, 12, 0, 'pt'),
    legend.position = 'top',
    legend.justification = 'left',
    legend.margin = margin(4, 0, 0, 0, 'pt'),
    legend.key.size = unit(1, 'lines'),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10, margin = margin(0, 0, 0, 0, 'pt')),
    axis.text = element_text(size = 10, margin = margin(2, 0, 2, 0, 'pt')),
    axis.ticks.length = unit(-4, 'pt')
  )
# histogram template
theme_bar <- theme_economist_white() +
  theme(
    text = element_text(family = 'YaHei'),
    plot.title = element_text(face = 'bold', size = 14),
    plot.subtitle = element_text(size = 12),
    plot.caption = element_text(
      hjust = 0,
      size = 10,
      margin = margin(0, 0, 0, 0, 'pt')
    ),
    plot.margin = margin(12, 0, 12, 10, 'pt'),
    legend.position = 'top',
    legend.justification = 'left',
    legend.margin = margin(4, 0, 0, 0, 'pt'),
    legend.key.size = unit(0.7, 'lines'),
    legend.title = element_blank(),
    legend.text = element_text(size = 10, margin = margin(0, 8, 0, 4, 'pt')),
    axis.text = element_text(size = 10),
    axis.ticks.length = unit(0, 'pt') # 不要坐标轴须
  )
```

# 一元线性回归
 
## 探索性数据分析

```{r}
# data
consumption <-
  c(594, 638, 1122, 1155, 1408, 1595, 1969, 2078, 2585, 2530)
income <-
  c(800, 1100, 1400, 1700, 2000, 2300, 2600, 2900, 3200, 3500)

# 先画图
plot(income, consumption)
abline(lm(consumption ~ income))
cor(income, consumption) # 相关系数
```

## 线性回归模型的创建和查看

语法：`lm(formula, data, ...)`

formula 为回归表达式，一般是`y~x`，默认包含截距项；不需要截距项时要写成`y~-1+x`或`y~0+x`

```{r}
# 有截距项回归
lm_single <- lm(consumption ~ income)
lm_single # 显示最基本的两个系数
class(lm_single) # lm 类对象
str(lm_single) # 长度为12的列表，可以逐项展开观察

# 返回系数向量的两种写法
coef(lm_single)
lm_single$coefficients

# 概览回归结果
slm_single <- summary(lm_single)
class(slm_single) # summary.lm 类的对象
slm_single

# 系数详情
coef(slm_single)
slm_single$coefficients # 这是一个矩阵
slm_single$coef[, 2] # 第二列为系数的标准误

# 对\sigma的估计，有了这个参数才能计算系数的标准误
slm_single$sigma

# 模型系数的置信区间
confint(lm_single, level = 0.95) # 注意第一个参数是lm而非slm!


## 截距项不显著，故使用无截距项回归
lm(consumption ~ -1 + income) %>% summary()
# R^2更大了，所以去掉截距项是正确的
```

## OLS和MLE两种参数估计方法

```{r}
## 首先定义一个回调函数，传入模型参数向量，返回要取极值的表达式

# MLE，最大化对数似然函数(linklihood function)
mleFunction = function(para) {
  n = length(consumption)
  e = consumption - para[1] - para[2] * income # 残差
  return(-0.5 * n * log(2 * pi) - n * log(para[3]) - 0.5 * sum(e ^ 2) / (para[3] ^ 2))
  # 注意以上两行都是向量化计算
}
# maxLik()令似然函数取极值，估计出模型参数，建立回归模型
lm_mle = maxLik(mleFunction, start = c(0.1, 1, 1)) %T>% class()
coef(lm_mle) # 传入的3个参数，分别为截距项、一次项系数和\sigma的估计量


# OLS，最小化残差平方和
olsFunction = function(para) {
  e = consumption - para[1] - para[2] * income
  return(sum(e ^ 2))
}
optim(c(100, 1), olsFunction) # 这不是一个回归模型对象，但它能显示模型参数值
```

## 模型检验

### 拟合优度

```{r}
slm_single$r.squared
slm_single$adj.r.squared
```

### 变量显著性

看`slm$coef`展示的系数矩阵的三四列即可，使用了t检验

其实直接显示slm摘要更方面，直接给出是否显著的星号

```{r}
slm_single$coefficients
slm_single
```

## 模型预测

### 点预测

```{r}
# 以下三种写法等价
slm_single$coef[, 1][1] + slm_single$coef[, 1][2] * 4000
coef(lm_single)[1] + coef(lm_single)[2] * 4000
predict(lm_single, newdata = data.frame(income = 4000))


round(fitted(lm_single), 2) # 模型在样本点处的拟合值
round(resid(lm_single), 2) # 模型在样本点处的的残差
plot(lm_single)
```

### 区间预测

拟合值的条件均值的置信区间
`predict(..., interval = "prediction", level = 0.95)`

总体的条件期望的置信区间
`predict(..., interval = "confidence", level = 0.95)`

```{r}
predict(
  lm_single,
  newdata = data.frame(income = 4000),
  interval = "prediction",
  level = 0.95
)
predict(
  lm_single,
  newdata = data.frame(income = 4000),
  interval = "confidence",
  level = 0.95
)
```
## 作图

```{r}
par(mfrow = c(1, 1))
sx = sort(income)
prediction = predict(lm_single, data.frame(income = sx), interval = "prediction")
confidence = predict(lm_single, data.frame(income = sx), interval = "confidence")
plot(income, consumption)
abline(lm_single)
lines(sx, confidence[, 2])
lines(sx, confidence[, 3])
lines(sx, prediction[, 2], lty = 3)
lines(sx, prediction[, 3], lty = 3)
```

## 综合案例

```{r}
rm(list = ls())

# 探索性数据分析
data = read.table("medicine.txt", head = T)
attach(data)
plot(x, y, xlab = "人口数", ylab = "医疗机构数")
abline(lm(y ~ x));
cor(x, y)

# 建模和检验
lm = lm(y ~ x)
lm.summary = summary(lm)
lm.summary
lm.summary$r.squared
lm.summary$adj.r.squared

# 常数项不显著，重新建模
lm2 = lm(y ~ 0 + x)
lm2.summary = summary(lm2)
lm2.summary

# 作图
par(mfrow = c(1, 1))
sx = sort(x) 
pred = predict(lm2, data.frame(x = sx), interval = "prediction")
conf = predict(lm2, data.frame(x = sx), interval = "confidence")
plot(x, y)
abline(lm2)
lines(sx, conf[, 2])
lines(sx, conf[, 3])
lines(sx, pred[, 2], lty = 3)
lines(sx, pred[, 3], lty = 3)
detach()
```

# 多元线性回归

## 模型建构

```{r}
rm(list = ls())

data <- read.csv(file = "tax.csv")
lm3 = lm(tax ~ GDP + expand + CPI, data = data)
coef(lm3)
```

## 最大似然估计
```{r}
attach(data)

## MLE
loglik = function (para) {
  N = length(tax)
  e = tax - para[1] - para[2] * GDP - para[3] * expand - para[4] * CPI
  ll = -N * log(sqrt(2 * pi) * para[5]) - 0.5 * sum(e ^ 2)/ (para[5] ^ 2)
  return(ll)
}
mle3 = maxLik(loglik,
              start = c(6616, 0.04, 0.6, 58, 100), # 结果与初始值有关，并非全局最优
              iterlim = 10000)
mle3
coef(mle3)
detach()
```

## 模型检验

### 拟合优度

多元回归应该用adjusted $R^2$

```{r}
slm3 <- summary(lm3)
slm3$r.squared # 注意是在slm对象中提取，而非lm对象
slm3$adj.r.squared
```

### 整体显著性

F检验

```{r}
slm3
```

### 变量显著性

```{r}
slm3$coef
```


## 模型预测

### 点预测

```{r}
coef(lm3)[1] + coef(lm3)[2] * 520000 + coef(lm3)[3] * 130000 + coef(lm3)[4] *
  103
predict(lm3, newdata = data.frame(GDP = 520000, expand = 130000, CPI = 103))
```
### 区间预测

拟合值的条件均值的置信区间
predict(..., interval = "prediction")

总体的条件期望的置信区间
predict(..., interval = "confidence")

```{r}
predict(lm3, interval = "prediction") # 不指定第二个参数，就是样本内拟合
predict(lm3, interval = "confidence")
predict(lm3,
        newdata = data.frame(GDP = 520000, expand = 130000, CPI = 103),
        interval = "prediction")
predict(lm3,
        newdata = data.frame(GDP = 520000, expand = 130000, CPI = 103),
        interval = "confidence")
```

## 综合案例

```{r}
rm(list = ls())
par(mfrow = c(2, 3))

data = read.table("travel.txt", head = 1)
attach(data)

# 探索性数据分析
plot(x1, y, xlab = "国内旅游人数", ylab = "国内旅游收入")
abline(lm(y ~ x1))
plot(x2, y, xlab = "城镇居民人均旅游支出", ylab = "国内旅游收入")
abline(lm(y ~ x2))
plot(x3, y, xlab = "农村居民人均旅游支出", ylab = "国内旅游收入")
abline(lm(y ~ x3))
plot(x4, y, xlab = "公路里程", ylab = "国内旅游收入")
abline(lm(y ~ x4))
plot(x5, y, xlab = "铁路里程", ylab = "国内旅游收入")
abline(lm(y ~ x5))
c(cor(x1, y), cor(x2, y), cor(x3, y), cor(x4, y), cor(x5, y))
pairs(data[, 3:7]) # 散点图矩阵，可以观察哪些自变量之间存在强相关，可能导致多重共线性

# 建模
lm = lm(y ~ x1 + x2 + x3 + x4 + x5)
lm.summary = summary(lm)
lm.summary 

# 检验
lm.summary$r.squared
lm.summary$adj.r.squared

# 有三个系数不显著，可能存在多重共线性，下一章讨论
# 计算一下相关系数
c(cor(x1, x2), cor(x1, x3), cor(x4, x5))


# 重新建模
lm2 = lm(y ~ x2 + x3 + x4)
lm2.summary = summary(lm2)
lm2.summary
# 三项检验均通过

# 预测
conf = predict(lm2, data.frame(x2, x3, x4), interval = "confidence")
pred = predict(lm2, data.frame(x2, x3, x4), interval = "prediction") 
```


# 多重共线性 multicolinarity

## 原因

变量之间存在相关性

## 多重共线性的诊断

### 可决系数法

$R^2$较大、F值很高但每个系数的方差都很大、t值都很小。

```{r}
dat <- read.csv(file = "11-1.csv")
lm3 = lm(revenue ~ industry + agriculture + construction + consumption +
           pop + disaster,
         data = dat)
summary(lm3)
```

### 回归检验法

以某个解释变量$x_k$对其他解释变量进行线性回归，若共有p个解释变量，则进行p次回归。若存在显著的回归方程，则说明存在多重共线性；若p个回归模型都不显著，说明不存在多重共线性。

这种方法**不仅能检验多重共线性，还能确定究竟是哪些变量引起了多重共线性**。

```{r}
xNames <- colnames(dat)[2:7]
lms <- list()

for (i in 1:6) {
  lms[[i]] <- lm(
    dat %>% extract2(xNames[i]) ~
      dat %>% extract2(xNames[-i][1]) +
      dat %>% extract2(xNames[-i][2]) +
      dat %>% extract2(xNames[-i][3]) +
      dat %>% extract2(xNames[-i][4]) +
      dat %>% extract2(xNames[-i][5])
  )
}

index <- map_dbl(lms, function(lm) {
  return(summary(lm)$adj.r.squared)
}) %>%
  which.max()

cat(index); cat("\n")
```
因此，第三个解释变量与其他解释变量之间的回归方程最好地反映了变量之间的多重共线性。

### 特征根法

矩阵$X'X$至少有一个特征根近似为0

```{r}
x <- cbind(rep(1, length(dat[, 1])), dat[, -c(1, 8)])
x <- as.matrix(x)
eigen(t(x) %*% x) # 最后一个特征根近似为0
```

### 条件指数(Condition Index, CI)法 

矩阵$X'X$的最大特征根$\lambda_m$与特征根$\lambda_i$的商的平方根称为特征根$\lambda_i$的条件指数(Condition Index)，记为
$$
k_i = \sqrt {\frac{\lambda_m}{\lambda_i}}
$$
- $0<k<10$时，不存在多重共线性
- $10\leq k<100$时，存在较强的多重共线性
- $k\geq100$时，存在严重的多重共线性

```{r}
CI_7 <- sqrt(eigen(t(x) %*% x)$values[1] / eigen(t(x) %*% x)$values[7])
CI_7
```
远大于100，故存在严重的多重共线性。

### 方差膨胀因子(variance inflation factor, VIF)

$VIF_i \geq 10$时，就说明$x_i$与其余自变量之间存在严重的多重共线性。

```{r}
# car包和DAAG包均有vif()检验函数
car::vif(lm3)
DAAG::vif(lm3, digits = 5)
```

construction与其余变量的多重共线性最强，这与回归检验法得出的结论一致。

## 多重共线性的克服

### 逐步回归

forward逐步回归，逐个引入变量，

![](逐步回归.png)

backward逐步回归是先引入所有变量，然后逐个剔除。

both逐步回归是双向的（一切子集回归法，推荐这种方法）。`step(lm, direction = "both")`命令即可进行，省的自己写循环，非常方便。

```{r}
# 通过若干步比较，得出最优回归模型
lm_step <- step(lm3, direction = "both")
# 所有系数都是显著的
lm_step %>% summary()
# 但仍存在多重共线性
DAAG::vif(lm_step, digits = 5)
```

### 岭回归

![](岭回归1.png)
![](岭回归2.png)
![](岭回归3.png)

R里MASS包的lm.ridge()函数可以用来做岭估计，其用法与lm()用法类似。不指定$\lambda$时，默认为0

```{r}
library(MASS)

lm.r <-
  lm.ridge(revenue ~ industry + agriculture + construction + consumption +
             pop + disaster,
           data = dat)
lm.r

# 岭迹图
plot(
  lm.ridge(
    revenue ~ industry + agriculture + construction + consumption + pop + disaster,
    data = dat,
    lambda = seq(0, 0.3, 0.001)
  ),
  lwd = 3
)

# 给出最佳的\lambda
select(
  lm.ridge(
    revenue ~ industry + agriculture + construction + consumption + pop + disaster,
    data = dat,
    lambda = seq(0, 0.3, 0.001)
  )
)

# 使用最佳的\lambda做岭回归
lm.ridge(
  revenue ~ industry + agriculture + construction + consumption + pop + disaster,
  data = dat,
  lambda = 0.004
)
```

# 异方差 hetersdascity

## 异方差的诊断

### 图示法（定性、粗略）

#### 散点图

y对各解释变量作散点图。

```{r}
agricul <- read.csv(file = "11-2.csv")
y = agricul[, 2]
x = agricul[, 1]
plot(x, y) 
```
散点图的喇叭分布，表明数据存在异方差。
#### 残差图

各解释变量对残差平方或残差绝对值作散点图

```{r}
lm.a = lm(y ~ x)
summary(lm.a)
plot(resid(lm.a) ~ x)
```

残差也呈喇叭状分布

### Goldfeld-Quandt检验

```{r}
lmtest::gqtest(lm.a, order.by =  ~ x)
```

显著，拒绝原假设，认为存在异方差。

### Glejser检验

令残差绝对值对自变量进行对数化的暴力穷举回归，探索它们之间的函数关系。如果有显著的函数关系，即存在异方差。

Glejser 检验的特点是不仅能对异方差的存在进行判断，而且还能对异方差随解释变量变化的函数形式进行诊断。

```{r}
# 尝试检验一下残差与sqrt(x)的关系，很显著，可见二者存在函数关系
re = resid(lm.a)
abre = abs(re)
summary(lm(abre~I(sqrt(x))))
summary(lm(abre~-1+I(sqrt(x))))
```

### White检验

怀特检验的特点是，不仅能够检验异方差的存在，同时在多变量的情况下，还能够判断出是哪一个变量引起的异方差，通常适用于界面数据的情形。

该方法不需要异方差的先验信息，但要求观测值为大样本。

```{r}
# white检验拒绝原假设，认为存在异方差
lmtest::bptest(lm.a, ~x+I(x^2))
```


## 异方差的克服

### 广义最小二乘法

在Glejser检验中，发现残差绝对值与解释变量的函数关系：$\hat \epsilon_i = 0.2576\sqrt X_i$。因此把每个变量都除以$0.2576\sqrt X_i$（变换），消除异方差后再回归。

由此得到的映射关系，需要还原，才能应用于预测。

```{r}
ys <- y / (0.2576 * sqrt(x))
xs <- x / (0.2576 * sqrt(x))
plot(xs, ys)
lm.sa <- lm(ys ~ xs)
summary(lm.sa)
plot(xs, resid(lm.sa))

# white检验通过了，无法拒绝H0
lmtest::bptest(lm.sa,  ~ xs + I(xs ^ 2)) 
```


### 取对数

```{r}
lny <- log(y)
lnx <- log(x)
plot(lnx, lny)
lm.lna <- lm(lny ~ lnx)
summary(lm.lna)
plot(lnx, resid(lm.lna))

lmtest::bptest(lm.lna,  ~ lnx + I(lnx ^ 2))
```

# （误差项之间的）自相关

自相关指**随机误差项**$\epsilon_i$序列之间存在相关性，常见于时间序列数据。

从残差图可以看出残差的变动有系统模式，连续为正和连续为负。另外，从残差前后项之间的散点图可以看出，它们之间存在高度的正的线性关系。这些表明残差项存在一阶正自相关。

```{r}
dat = read.csv("./11-3.csv")
y = dat$expend
x = dat$income
p = dat$cpi
yp = y / p * 100
xp = x / p * 100
lm.in = lm(yp ~ xp)
summary(lm.in)

e <- resid(lm.in)
plot(e, type = "l")
abline(h = 0, col = "red")
plot(e[-1], e[-10])
```


## 自相关的原因

### 模型中未包含一些自相关的重要解释变量

如消费是收入的函数叠加一个随机误差，但现实中，这个误差项中其实包含了一些难以量化的印象因素，而这些影响因素可能并不是随机分布的。如繁荣期，人们预期乐观，误差项就会为正；萧条期，人们悲观，误差项为负。

### 变量惯性

如蛛网模型导致农产品产量和价格呈现跨期负相关。

## 自相关的诊断

### 图示法

残差序列图或者残差散点图。在残差散点图中，集中于1、3象限为正自相关；集中于2、4象限为负自相关。

### Durbin-Watson(DW)检验

检验随机误差项之间是否存在一阶自相关。

```{r}
dw <- lmtest::dwtest(lm.in)
dw
```


## 自相关的克服

如果序列相关是由于错误地设定模型的数学形式所致，那么就应当修改模型的数学形式。

如果序列相关是由于模型中省略了重要解释变量造成的，那么解决办法就是找出略去的解释变量，把它做为重要解释变量列入模型。

只有当以上两种引起序列相关的原因都消除后，才能认为误差项 “真正”存在序列相
关。然后使用广义差分法得到新的系数。

```{r}
# 结果不仅给出了新的系数，还给出了D-W检验的前后比较，从显著到不显著。可以认为自相关性基本消除。
orcutt::cochrane.orcutt(lm.in)
```

# 虚拟变量回归模型



